{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6228b0-559e-4499-884e-fdfc3c8abdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968954d4-8679-4b8b-964c-01b7f9f427b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wizard = load_dataset(\"md_gender_bias\", \"wizard\")\n",
    "hf_splits = [\"train\", \"validation\", \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be295be3-dbea-4ec0-b301-6dc0bea5a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Process wizard of wikipedia\n",
    "# text, chosen_topic, gender\n",
    "# assemble text based on topic, when topic changes new text\n",
    "# assert all gender labels the same and assign new gender\n",
    "def merge_topics(data):\n",
    "    curr_topic = data[0][\"chosen_topic\"] \n",
    "    all_data = []\n",
    "    texts, genders = [], []\n",
    "    for entry in data:\n",
    "        if entry[\"chosen_topic\"] != curr_topic: # save and reset\n",
    "            uniq_genders = set(genders)\n",
    "            if len(uniq_genders) > 1:\n",
    "                assert f\"too many genders for topic {curr_topic}. Genders found: {genders}\"\n",
    "            all_data.append({\n",
    "                \"text\": \"\\n\".join(texts),\n",
    "                \"chosen_topic\": curr_topic,\n",
    "                \"gender\": uniq_genders.pop()\n",
    "            })\n",
    "            curr_topic = entry[\"chosen_topic\"]\n",
    "            texts, genders = [], []\n",
    "        else:\n",
    "            texts.append(entry[\"text\"])\n",
    "            genders.append(entry[\"gender\"])\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d407a5a-26d5-4a8e-9f39-f7d86d933c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_stats(ds):\n",
    "    all_lengths = []\n",
    "    for split in splits:\n",
    "        ds_lengths = [len(sent['text'].split()) for sent in ds]\n",
    "        all_lengths.extend(ds_lengths)\n",
    "    m, med = np.mean(all_lengths), np.median(all_lengths)\n",
    "    #w = Counter(a_lengths)\n",
    "    print(f\"Mean: {m} Median: {med}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf72fe-f319-48f1-9687-65fb488e33c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = merge_topics(wizard[\"train\"])\n",
    "merged_val = merge_topics(wizard[\"validation\"])\n",
    "merged_test = merge_topics(wizard[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc34d6-8ba2-4733-83e2-f915066cdb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example saving\n",
    "with open(\"data/md_gender/wizard.test.pickle\", \"wb\") as fout:\n",
    "    pickle.dump(merged_test, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff93acee-cf37-4cc9-8a97-80c32bd15265",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dataset_stats(wizard[\"train\"])\n",
    "print_dataset_stats(merged_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389e70c-f380-4146-a6c3-4cd40dbf3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter out gender neutral ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e031dca2-d0d1-4b6b-8670-67aa8d49d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_ints(x):\n",
    "    if x[\"gender\"] == 2:\n",
    "        x[\"gender\"] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12700d48-e38c-459b-8ff2-e156f76f8454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gender_neutral(ds):\n",
    "    new_ds = filter(lambda x: x[\"gender\"] > 0, ds)\n",
    "    new_ds = map(change_ints, new_ds)\n",
    "    return list(new_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77cedec-d676-45fe-b062-59b44581df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ds = filter_gender_neutral(merged_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1cb62-ddf1-47b4-af14-ec0c14d2fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/md_gender/wizard_binary/train.pickle\", \"wb\") as fout:\n",
    "    pickle.dump(filtered_ds, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb906871-3f3b-451e-a90a-9d0187c9f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Wikipedia processing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af43960-1ad6-4df2-8626-de1377c89d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label, label2int):\n",
    "    if label in label2int:\n",
    "        return label2int[label]\n",
    "    else:\n",
    "        print(f\"adding new label {label}\")\n",
    "        max_int = max(label2int.values())\n",
    "        label2int[label] = max_int + 1\n",
    "        return max_int + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f184b71-a860-4e56-a656-90a360ac75a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int = {\n",
    "    \"ABOUT:male\": 0,\n",
    "    \"ABOUT:female\": 1,\n",
    "    \"ABOUT:gender-neutral\": 2\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af0aea-43dd-4fe0-8b79-8f93ed960f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_samples = {\n",
    "    \"text\": [],\n",
    "    \"gender\": []\n",
    "}\n",
    "long_samples = {\n",
    "    \"text\": [],\n",
    "    \"gender\": []\n",
    "}\n",
    "short_text_lens, long_text_lens = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd464315-7963-4463-acfd-bdb4716e9149",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wiki_out_log\", \"r\") as fin:\n",
    "    wiki = fin.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543997c-b782-471f-8e58-6b3c39a916e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split on tabs, then on :, then text is 1 and label is 2, then convert label2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9762f83-8a8a-443b-9a8b-ff74592c0928",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, line in tqdm(enumerate(wiki)):\n",
    "    if not line:\n",
    "        continue\n",
    "    data = line.split(\"\\t\")\n",
    "    nitems = len(data)\n",
    "    if nitems < 4:\n",
    "        if nitems > 1:\n",
    "            print(f\"unexpected data length of {nitems}\")\n",
    "        continue\n",
    "    text = data[1].split(\":\")[1]\n",
    "    label = data[2].split(\":\", 1)[1]\n",
    "    label = convert_label(label, label2int)\n",
    "    # filter texts too short\n",
    "    nwords = len(text.split())\n",
    "    if nwords < 10:\n",
    "        short_samples[\"text\"].append(text)\n",
    "        short_samples[\"gender\"].append(label)\n",
    "        short_text_lens.append(nwords)\n",
    "    else:\n",
    "        long_samples[\"text\"].append(text)\n",
    "        long_samples[\"gender\"].append(label)\n",
    "        long_text_lens.append(nwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871d5bd-0bf5-4494-b4b1-3f85d304a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e881d-7257-4cf7-ba4e-9d71f7e60e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_val_test, label_train, label_val_test = train_test_split(long_samples[\"text\"], long_samples[\"gender\"], test_size=0.35)\n",
    "text_test, text_val, label_test, label_val = train_test_split(text_val_test, label_val_test, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9fb347-ed49-4e73-889d-ec92e43e999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_splits = {\n",
    "    \"train\": [],\n",
    "    \"dev\": [],\n",
    "    \"test\": [],\n",
    "}\n",
    "wiki_splits[\"test\"] = [{\"text\": i, \"gender\": j} for i,j in zip(text_test, label_test)]\n",
    "wiki_splits[\"train\"] = [{\"text\": i, \"gender\": j} for i,j in zip(text_train, label_train)]\n",
    "wiki_splits[\"dev\"] = [{\"text\": i, \"gender\": j} for i,j in zip(text_val, label_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50332d22-2eb7-404d-b113-4c184e36494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    with open(f\"data/md_gender/wikipedia/{split}.pickle\", \"wb\") as fout:\n",
    "        this_split = wiki_splits[split]\n",
    "        pickle.dump(this_split, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8c5e8-13a1-445a-8c42-ed31b1b1e779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sgt",
   "language": "python",
   "name": "sgt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
