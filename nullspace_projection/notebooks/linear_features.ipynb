{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"../data/embeddings\")\n",
    "sys.path.append(\"../data/embeddings/biasbios\")\n",
    "import classifier\n",
    "\n",
    "import debias\n",
    "\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pytorch_transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "import scipy\n",
    "from scipy import linalg\n",
    "from scipy import sparse\n",
    "from scipy.stats.stats import pearsonr\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, Perceptron, LogisticRegression\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict\n",
    "\n",
    "import copy\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFS = ['professor', 'physician', 'attorney', 'photographer', 'journalist', 'nurse', 'psychologist', 'teacher',\n",
    "'dentist', 'surgeon', 'architect', 'painter', 'model', 'poet', 'filmmaker', 'software_engineer',\n",
    "'accountant', 'composer', 'dietitian', 'comedian', 'chiropractor', 'pastor', 'paralegal', 'yoga_teacher',\n",
    "'dj', 'interior_designer', 'personal_trainer', 'rapper']\n",
    "\n",
    "PROF2UNIFIED_PROF = {\"associate professor\": \"professor\", \"assistant professor\": \"professor\", \"software engineer\": \"software_engineer\", \"psychotherapist\": \"psychologist\", \"orthopedic surgeon\": \"surgeon\", \"trial lawyer\": \"attorney\",\"plastic surgeon\": \"surgeon\",  \"trial attorney\": \"attorney\", \"senior software engineer\": \"software_engineer\", \"interior designer\": \"interior_designer\", \"certified public accountant\": \"accountant\", \"cpa\": \"accountant\", \"neurosurgeon\": \"surgeon\", \"yoga teacher\": \"yoga_teacher\", \"nutritionist\": \"dietitian\", \"personal trainer\": \"personal_trainer\", \"certified personal trainer\": \"personal_trainer\", \"yoga instructor\": \"yoga_teacher\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    with open(fname, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data        \n",
    "        \n",
    "    \n",
    "def count_profs_and_gender(data: List[dict]):\n",
    "    \n",
    "    counter = defaultdict(Counter)\n",
    "    for entry in data:\n",
    "        gender, prof = entry[\"gender\"], entry[\"raw_title\"]\n",
    "        counter[prof.lower()][gender.lower()] += 1\n",
    "        \n",
    "    return counter\n",
    "\n",
    "def filter_dataset(data, topk = 10):\n",
    "    \n",
    "    filtered = []\n",
    "    counter = count_profs_and_gender(data)\n",
    "    total_counts = [(prof, counter[prof][\"f\"] + counter[prof][\"m\"]) for prof in counter.keys()]\n",
    "    profs_by_frq = sorted(total_counts, key = lambda x: -x[1])\n",
    "    topk_profs = [p[0] for p in profs_by_frq[:topk]]\n",
    "    \n",
    "    print(\"Top-k professions: {}\".format(topk_profs))\n",
    "    for d in data:\n",
    "        \n",
    "        if d[\"raw_title\"].lower() in topk_profs:\n",
    "            filtered.append(d)\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dictionary(path):\n",
    "    \n",
    "    with open(path, \"r\", encoding = \"utf-8\") as f:\n",
    "        \n",
    "        lines = f.readlines()\n",
    "        \n",
    "    k2v, v2k = {}, {}\n",
    "    for line in lines:\n",
    "        \n",
    "        k,v = line.strip().split(\"\\t\")\n",
    "        v = int(v)\n",
    "        k2v[k] = v\n",
    "        v2k[v] = k\n",
    "    \n",
    "    return k2v, v2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data('../data/biasbios/train.pickle')\n",
    "dev = load_data('../data/biasbios/dev.pickle')\n",
    "test = load_data('../data/biasbios/test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2i, i2p = load_dictionary(\"../data/biasbios/profession2index.txt\")\n",
    "g2i, i2g = load_dictionary(\"../data/biasbios/gender2index.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'g': 'f',\n",
       " 'p': 'professor',\n",
       " 'text': 'Dr. Elizabeth Armstrong-Mensah is a clinical assistant professor in the Undergraduate Program at the School of Public Health at Georgia State University. She teaches Introduction to Chronic and Infectious Diseases, Health Equity and Disparities: Urban and Global Health Challenges, and Introduction to Program Implementation and Evaluation. Dr. Armstrong-Mensah previously taught Global Health to students enrolled in the Schools Master of Public Health Program.',\n",
       " 'start': 153,\n",
       " 'hard_text': 'She teaches Introduction to Chronic and Infectious Diseases, Health Equity and Disparities: Urban and Global Health Challenges, and Introduction to Program Implementation and Evaluation. Dr. Armstrong-Mensah previously taught Global Health to students enrolled in the Schools Master of Public Health Program.',\n",
       " 'text_without_gender': '_ teaches Introduction to Chronic and Infectious Diseases, Health Equity and Disparities: Urban and Global Health Challenges, and Introduction to Program Implementation and Evaluation. Dr. _ previously taught Global Health to students enrolled in the Schools Master of Public Health Program.',\n",
       " 'hard_text_tokenized': 'She teaches Introduction to Chronic and Infectious Diseases , Health Equity and Disparities : Urban and Global Health Challenges , and Introduction to Program Implementation and Evaluation . Dr. Armstrong - Mensah previously taught Global Health to students enrolled in the Schools Master of Public Health Program .'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accountant': 0, 'architect': 1, 'attorney': 2, 'chiropractor': 3, 'comedian': 4, 'composer': 5, 'dentist': 6, 'dietitian': 7, 'dj': 8, 'filmmaker': 9, 'interior_designer': 10, 'journalist': 11, 'model': 12, 'nurse': 13, 'painter': 14, 'paralegal': 15, 'pastor': 16, 'personal_trainer': 17, 'photographer': 18, 'physician': 19, 'poet': 20, 'professor': 21, 'psychologist': 22, 'rapper': 23, 'software_engineer': 24, 'surgeon': 25, 'teacher': 26, 'yoga_teacher': 27}\n"
     ]
    }
   ],
   "source": [
    "print(p2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get input representatons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def nltk_tokenization(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def built_in_tokenization(text):\n",
    "    tokens = text.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 11s, sys: 5.86 s, total: 6min 17s\n",
      "Wall time: 29.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8065138966515929"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "x_train = [x['hard_text_tokenized'] for x in train]\n",
    "y_train = [x['p'] for x in train]\n",
    "\n",
    "x_dev = [x['hard_text_tokenized'] for x in dev]\n",
    "y_dev = [x['p'] for x in dev]\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=built_in_tokenization)),\n",
    "    ('selection', SelectKBest(chi2, k=10000)),\n",
    "#     ('classifier', LogisticRegression())\n",
    "    ('classifier', SGDClassifier(warm_start=True, loss='log', n_jobs=64, max_iter=75, random_state=0))\n",
    "])\n",
    "\n",
    "# clf.fit(x_train[:10000], y_train[:10000])\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [x['hard_text'] for x in test]\n",
    "y_test = [x['p'] for x in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7828499984752844"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perform debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old  Debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import old_debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_one_hot = clf.named_steps['selection'].transform(clf.named_steps['vectorizer'].transform([x['hard_text_tokenized'] for x in train]))\n",
    "x_dev_one_hot = clf.named_steps['selection'].transform(clf.named_steps['vectorizer'].transform([x['hard_text_tokenized'] for x in dev]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projection_matrix(num_clfs, X_train, Y_train, X_dev, Y_dev, Y_train_main, Y_dev_main, dim=300):\n",
    "\n",
    "    is_autoregressive = True\n",
    "    reg = \"l2\"\n",
    "    min_acc = 0.\n",
    "    noise = False\n",
    "    random_subset = False\n",
    "    regression = False\n",
    "    \n",
    "    clf = SGDClassifier\n",
    "    params = {'warm_start': True, 'loss': 'log', 'n_jobs': 64, 'max_iter': 100, 'random_state': 0}\n",
    "\n",
    "    P = old_debias.get_debiasing_projection(clf, params, num_clfs, dim, is_autoregressive,\n",
    "                                           min_acc, X_train, Y_train, X_dev, Y_dev,\n",
    "                                           by_class=True, Y_train_main=Y_train_main, Y_dev_main=Y_dev_main)\n",
    "    return P\n",
    "\n",
    "\n",
    "\n",
    "num_clfs = 40\n",
    "Y_dev_gender = np.array([d[\"g\"] for d in dev])\n",
    "Y_train_gender = np.array([d[\"g\"] for d in train])\n",
    "Y_dev_prof = np.array([d[\"p\"] for d in dev])\n",
    "Y_train_prof = np.array([d[\"p\"] for d in train])\n",
    "\n",
    "n_examples = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 0, accuracy: 0.9969259692088817:   2%|▎         | 1/40 [00:36<23:39, 36.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1, accuracy: 0.9922768152024796:   5%|▌         | 2/40 [03:38<50:40, 80.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 2, accuracy: 0.9701488745490575:   8%|▊         | 3/40 [06:38<1:07:48, 109.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 3, accuracy: 0.9497230831766679:  10%|█         | 4/40 [09:43<1:19:30, 132.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 4, accuracy: 0.9440831258574259:  12%|█▎        | 5/40 [13:03<1:29:09, 152.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 5, accuracy: 0.9139525430618363:  15%|█▌        | 6/40 [16:22<1:34:31, 166.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 6, accuracy: 0.9117930999441085:  18%|█▊        | 7/40 [19:38<1:36:33, 175.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 7, accuracy: 0.912910929322697:  20%|██        | 8/40 [22:50<1:36:14, 180.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 8, accuracy: 0.9118185051572583:  22%|██▎       | 9/40 [26:00<1:34:44, 183.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 9, accuracy: 0.9010212895686195:  25%|██▌       | 10/40 [29:21<1:34:16, 188.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 10, accuracy: 0.8774198465525126:  28%|██▊       | 11/40 [32:26<1:30:38, 187.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 11, accuracy: 0.8514811239266298:  30%|███       | 12/40 [35:30<1:26:56, 186.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 12, accuracy: 0.827955896549972:  32%|███▎      | 13/40 [38:31<1:23:10, 184.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 13, accuracy: 0.8070982165540369:  35%|███▌      | 14/40 [41:31<1:19:29, 183.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 14, accuracy: 0.7864183730501499:  38%|███▊      | 15/40 [44:33<1:16:10, 182.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 15, accuracy: 0.7638585437731823:  40%|████      | 16/40 [47:49<1:14:47, 186.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 16, accuracy: 0.7468116457497078:  42%|████▎     | 17/40 [50:52<1:11:14, 185.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 17, accuracy: 0.7296885320867842:  45%|████▌     | 18/40 [53:57<1:07:59, 185.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 18, accuracy: 0.7136832478024491:  48%|████▊     | 19/40 [57:14<1:06:10, 189.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 19, accuracy: 0.7013871246379757:  50%|█████     | 20/40 [1:00:19<1:02:35, 187.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 20, accuracy: 0.6861694019612825:  52%|█████▎    | 21/40 [1:03:20<58:45, 185.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 21, accuracy: 0.6754229967989431:  55%|█████▌    | 22/40 [1:06:18<55:02, 183.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 22, accuracy: 0.6635587622580154:  57%|█████▊    | 23/40 [1:09:16<51:32, 181.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 23, accuracy: 0.6568263807733347:  60%|██████    | 24/40 [1:12:18<48:30, 181.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 24, accuracy: 0.6478837457446268:  62%|██████▎   | 25/40 [1:15:35<46:32, 186.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 25, accuracy: 0.6398302931761598:  65%|██████▌   | 26/40 [1:18:38<43:17, 185.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 26, accuracy: 0.6324119709364362:  68%|██████▊   | 27/40 [1:21:43<40:09, 185.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 27, accuracy: 0.6259082363701032:  70%|███████   | 28/40 [1:24:51<37:10, 185.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 28, accuracy: 0.6180326202936842:  72%|███████▎  | 29/40 [1:27:54<33:56, 185.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 29, accuracy: 0.6115034805142016:  75%|███████▌  | 30/40 [1:30:53<30:33, 183.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 30, accuracy: 0.6049743407347188:  78%|███████▊  | 31/40 [1:33:55<27:25, 182.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 31, accuracy: 0.5988770895787816:  80%|████████  | 32/40 [1:37:07<24:43, 185.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 32, accuracy: 0.5952949545246684:  82%|████████▎ | 33/40 [1:40:09<21:32, 184.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 33, accuracy: 0.5897566180580255:  85%|████████▌ | 34/40 [1:43:29<18:55, 189.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 34, accuracy: 0.5872923123825009:  88%|████████▊ | 35/40 [1:47:01<16:20, 196.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 35, accuracy: 0.5820588384736548:  90%|█████████ | 36/40 [1:50:14<13:00, 195.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "iteration: 36, accuracy: 0.5787815659773385:  90%|█████████ | 36/40 [1:52:40<13:00, 195.12s/it]"
     ]
    }
   ],
   "source": [
    "# To calculate a new projection matrix\n",
    "# %%time\n",
    "\n",
    "P = get_projection_matrix(40, x_train_one_hot[:n_examples],\n",
    "                          Y_train_gender[:n_examples], x_dev_one_hot[:n_examples], Y_dev_gender[:n_examples],\n",
    "                             Y_train_prof[:n_examples], Y_dev_prof[:n_examples], dim = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the already calculated matrix\n",
    "P = np.load('P_linear.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning before and after projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiased_train = x_train_one_hot.dot(P)\n",
    "debiased_dev = x_dev_one_hot.dot(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'warm_start': True, 'loss': 'log', 'n_jobs': 64, 'max_iter': 75, 'random_state': 0}\n",
    "temp = SGDClassifier(**params)\n",
    "\n",
    "temp.fit(x_train_one_hot[:n_examples], Y_train_gender[:n_examples])\n",
    "temp.score(x_dev_one_hot, Y_dev_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'warm_start': True, 'loss': 'log', 'n_jobs': 64, 'max_iter': 75, 'random_state': 0}\n",
    "temp = SGDClassifier(**params)\n",
    "\n",
    "temp.fit(debiased_train[:n_examples], Y_train_gender[:n_examples])\n",
    "temp.score(debiased_dev, Y_dev_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'warm_start': True, 'loss': 'log', 'n_jobs': 64, 'max_iter': 75, 'random_state': 0}\n",
    "temp = SGDClassifier(**params)\n",
    "\n",
    "temp.fit(x_train_one_hot[:n_examples], Y_train_prof[:n_examples])\n",
    "temp.score(x_dev_one_hot, Y_dev_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'warm_start': True, 'loss': 'log', 'n_jobs': 64, 'max_iter': 75, 'random_state': 0}\n",
    "temp = SGDClassifier(**params)\n",
    "\n",
    "temp.fit(debiased_train[:n_examples], Y_train_prof[:n_examples])\n",
    "temp.score(debiased_dev, Y_dev_prof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New model - with debisaing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = clf.named_steps['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "debiased_svc = deepcopy(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiased_svc.coef_ = svc.coef_.dot(P.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debias_clf = Pipeline([\n",
    "    ('vectorizer', clf.named_steps['vectorizer']),\n",
    "    ('selection', clf.named_steps['selection']),\n",
    "    ('classifier', debiased_svc),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "debias_clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debias_ft_clf = Pipeline([\n",
    "    ('vectorizer', clf.named_steps['vectorizer']),\n",
    "    ('selection', clf.named_steps['selection']),\n",
    "    ('classifier', debiased_svc),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test model without finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_bias = clf.score(x_test, y_test)\n",
    "acc_test_debias = debias_clf.score(x_test, y_test)\n",
    "\n",
    "print(acc_test_bias, acc_test_debias, acc_test_bias - acc_test_debias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_cls = clf.named_steps['classifier']\n",
    "debias_cls = debias_clf.named_steps['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = clf.named_steps['vectorizer']\n",
    "selector = clf.named_steps['selection']\n",
    "feat_names = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab_10k.txt', 'w') as f:\n",
    "    for w in feature_names:\n",
    "        f.write(w + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum weight change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.argsort(np.abs(debias_cls.coef_ - reg_cls.coef_)[0, :])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# a specific profession most changed words\n",
    "for ind in np.argsort(np.abs(debias_cls.coef_ - reg_cls.coef_)[2, :])[::-1][:20]:\n",
    "    print(feat_names[selector.get_support()][ind], ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = feat_names[selector.get_support()]\n",
    "coefs_diff = np.abs(debias_cls.coef_ - reg_cls.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_debiased_words = defaultdict(int)\n",
    "for i in range(reg_cls.coef_.shape[0]):\n",
    "    for ind_val, index in enumerate(np.argsort(coefs_diff[i, :])[::-1]):\n",
    "        top_debiased_words[feature_names[index]] += coefs_diff[i, index]\n",
    "        \n",
    "for k, v in top_debiased_words.items():\n",
    "    top_debiased_words[k] /= float(reg_cls.coef_.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_x = sorted(top_debiased_words.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print([x[0] for x in sorted_x[:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, (x, _) in enumerate(sorted_x[:100]):\n",
    "    print(x + ', ', end='')\n",
    "    if ind > 0 and ind % 6 == 0:\n",
    "        print('\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gender_file(in_f):\n",
    "    with open(in_f) as f:\n",
    "        data = f.readlines()\n",
    "    words = [x.strip() for x in data]\n",
    "    return words[:500]\n",
    "        \n",
    "    \n",
    "female_words = read_gender_file('female-biased.glove.1000.txt')\n",
    "male_words = read_gender_file('male-biased.glove.1000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(male_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(female_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('self_vocab.txt', 'w') as f:\n",
    "    for x in feat_names[selector.get_support()]:\n",
    "        f.write(x + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendered_words = male_words + female_words\n",
    "\n",
    "feats_name_10k = feat_names[selector.get_support()]\n",
    "gendered_feats = []\n",
    "for gen in gendered_words:\n",
    "    val = np.where(feats_name_10k == gen)[0]\n",
    "    if len(val) > 0:\n",
    "        gendered_feats.append(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "no_gendered_feats = np.random.randint(10000, size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(gendered_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(no_gendered_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gender_change = 0\n",
    "gender_change_list = np.abs(debias_cls.coef_ - reg_cls.coef_)[5, :]\n",
    "for ind in gendered_feats:\n",
    "    gender_change += gender_change_list[ind]\n",
    "    \n",
    "gender_change /= len(gendered_feats)\n",
    "print(gender_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_change_list.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_change / gender_change_list.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_change = []\n",
    "for i in range(reg_cls.coef_.shape[0]):\n",
    "    gender_change_list = np.abs(debias_cls.coef_ - reg_cls.coef_)[i, :]\n",
    "    gender_change = 0\n",
    "    for ind in gendered_feats:\n",
    "        gender_change += gender_change_list[ind]\n",
    "    gender_change /= len(gendered_feats)\n",
    "    profession_change.append(gender_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_no_change = []\n",
    "for i in range(reg_cls.coef_.shape[0]):\n",
    "    gender_unchange_list = np.abs(debias_cls.coef_ - reg_cls.coef_)[i, :]\n",
    "    gender_unchange = 0\n",
    "    for ind in no_gendered_feats:\n",
    "        gender_unchange += gender_unchange_list[ind]\n",
    "    gender_unchange /= len(no_gendered_feats)\n",
    "    profession_no_change.append(gender_unchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_word_change = np.abs(debias_cls.coef_ - reg_cls.coef_).mean(axis=1)\n",
    "\n",
    "profession_change_diff = np.array(profession_change) / mean_word_change\n",
    "profession_unchange_diff = np.array(profession_no_change) / mean_word_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2plot(change, unchange, professions):\n",
    "    \n",
    "\n",
    "#     ax = plt.plot(professions, [1] * len(change), '.--', label='mean change')\n",
    "    ax = plt.plot(professions, change, '*:', label='biased words', linestyle='None')\n",
    "    ax = plt.plot(professions, unchange, '+:', label='random words', linestyle='None')\n",
    "\n",
    "#     plt.annotate('100%', size=8,\n",
    "#     ha = 'center', va = 'bottom',\n",
    "#     xytext = (65, 0.455),\n",
    "#     xy = (75.2, 0.479),\n",
    "#     arrowprops = { 'facecolor' : 'black', 'shrink' : 0.001, 'width': 0.5, 'headwidth': 6, 'headlength': 8 })\n",
    "\n",
    "    plt.ylabel('Change relative to mean')\n",
    "    plt.xlabel('Profession')\n",
    "    plt.title('Relative weight change')\n",
    "    \n",
    "    plt.axhline(y=1, xmax=1.0, color='black', ls='--')\n",
    "    plt.text(25, 1.025, 'no-change', fontsize=10, va='center', ha='center')#, backgroundcolor='')\n",
    "    \n",
    "#     plt.ylim(0.5,0.90)\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=75, fontsize=9)\n",
    "    plt.ylim(0.8, 1.55)\n",
    "    \n",
    "    plt.savefig('diff_change.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "data2plot(profession_change_diff, profession_unchange_diff, list(p2i.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_change_diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_unchange_diff.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPR Calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_profs_and_gender(data: List[dict]):\n",
    "    \n",
    "    counter = defaultdict(Counter)\n",
    "    for entry in data:\n",
    "        gender, prof = entry[\"g\"], entry[\"p\"]\n",
    "        counter[prof][gender] += 1\n",
    "        \n",
    "    return counter\n",
    "\n",
    "prof_gender_count = count_profs_and_gender(train+dev+test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_gender_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,m = 0., 0.\n",
    "prof2fem = dict()\n",
    "\n",
    "for k, values in prof_gender_count.items():\n",
    "    f += values['f']\n",
    "    m += values['m']\n",
    "    prof2fem[k] = values['f']/(values['f'] + values['m'])\n",
    "\n",
    "print(f / (f + m))\n",
    "print(prof2fem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TPR(y_pred, y_true, p2i, i2p, gender):\n",
    "    \n",
    "    scores = defaultdict(Counter)\n",
    "    prof_count_total = defaultdict(Counter)\n",
    "    \n",
    "    for y_hat, y, g in zip(y_pred, y_true, gender):\n",
    "        \n",
    "        if y == y_hat:\n",
    "            \n",
    "            scores[p2i[y]][g] += 1\n",
    "        \n",
    "        prof_count_total[p2i[y]][g] += 1\n",
    "    \n",
    "    tprs = defaultdict(dict)\n",
    "    tprs_change = dict()\n",
    "    tprs_ratio = []\n",
    "    \n",
    "    for profession, scores_dict in scores.items():\n",
    "        \n",
    "        good_m, good_f = scores_dict[\"m\"], scores_dict[\"f\"]\n",
    "        prof_total_f = prof_count_total[profession][\"f\"]\n",
    "        prof_total_m = prof_count_total[profession][\"m\"]\n",
    "        tpr_m = (good_m) / prof_total_m\n",
    "        tpr_f = (good_f) / prof_total_f\n",
    "        \n",
    "        tprs[profession][\"m\"] = tpr_m\n",
    "        tprs[profession][\"f\"] = tpr_f\n",
    "#         print(tpr_m, tpr_f)\n",
    "        tprs_ratio.append(tpr_m/tpr_f)\n",
    "#         tprs_ratio.append(tpr_f/tpr_m)\n",
    "        tprs_change[profession] = tpr_m - tpr_f\n",
    "        \n",
    "    return tprs, tprs_change, np.mean(np.abs(tprs_ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = len(dev)\n",
    "y_pred = debias_clf.predict(x_dev[:k])\n",
    "tprs_debias, tprs_change_debias, mean_tprs_debias = get_TPR(y_pred, y_dev[:k], p2i, i2p, [x['g'] for x in dev[:k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = len(dev)\n",
    "y_pred = clf.predict(x_dev[:k])\n",
    "tprs_biased, tprs_change_biased, mean_tprs_biased = get_TPR(y_pred, y_dev[:k], p2i, i2p, [x['g'] for x in dev[:k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(test)\n",
    "y_pred = clf.predict(x_test[:k])\n",
    "tprs_biased, tprs_change_biased, mean_tprs_biased = get_TPR(y_pred, y_test[:k], p2i, i2p, [x['g'] for x in test[:k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(test)\n",
    "y_pred = debias_clf.predict(x_test[:k])\n",
    "tprs_debias, tprs_change_debias, mean_tprs_debias = get_TPR(y_pred, y_test[:k], p2i, i2p, [x['g'] for x in test[:k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_vs_tpr(tprs, title, measure, prof2fem):\n",
    "    \n",
    "    professions = list(tprs.keys())\n",
    "    #\n",
    "    \"\"\" \n",
    "    sims = dict()\n",
    "    gender_direction = word2vec[\"he\"] - word2vec[\"she\"]\n",
    "    \n",
    "    for p in professions:\n",
    "        sim = word2vec.cosine_similarities(word2vec[p], [gender_direction])[0]\n",
    "        sims[p] = sim\n",
    "    \"\"\"\n",
    "    tpr_lst = [tprs[p] for p in professions]\n",
    "    sim_lst = [prof2fem[i2p[p]] for p in professions]\n",
    "    \n",
    "#     print(sim_lst)\n",
    "    print(tpr_lst)\n",
    "\n",
    "    #professions = [p.replace(\"_\", \" \") for p in professions if p in word2vec]\n",
    "    \n",
    "    plt.plot(sim_lst, tpr_lst, marker = \"o\", linestyle = \"none\")\n",
    "    plt.xlabel(\"% women\", fontsize = 13)\n",
    "    plt.ylabel(\"{}_diff_female {}\".format(measure, title), fontsize = 13)\n",
    "#     for p in professions:\n",
    "#         x,y = prof2fem[p], tprs[p]\n",
    "#         plt.annotate(p , (x,y), size = 4, color = \"red\")\n",
    "#     plt.savefig(\"{}_vs_bias_{}\".format(measure, title), dpi = 600)\n",
    "    print(\"Correlation: {}; p-value: {}\".format(*pearsonr(sim_lst, tpr_lst)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "similarity_vs_tpr(tprs_change_biased, '', 'a', prof2fem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similarity_vs_tpr(tprs_change_debias, '', 'a', prof2fem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_diff(tpr_diff):\n",
    "    return np.sqrt(np.mean(tpr_diff**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before', rms_diff(np.array(list(tprs_change_biased.values()))))\n",
    "print('after', rms_diff(np.array(list(tprs_change_debias.values()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train.dot(P), Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.score(X_dev.dot(P), Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nullspace",
   "language": "python",
   "name": "nullspace"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
